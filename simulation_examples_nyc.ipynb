{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library doing the computing\n",
    "import wte\n",
    "import bz2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic variables -- adjust these for the environment\n",
    "base_dir = \"data/\" # base directory where all data files are\n",
    "# directory for travel time and index matrices\n",
    "fnbase = base_dir + \"nyc_travel_times\"\n",
    "# file with travel distances\n",
    "dist_fn = base_dir + \"nyc_travel_times/distances_dir.bin\"\n",
    "# size of the matrices (i.e. nodes in the network)\n",
    "matrix_size = 4092\n",
    "# trips to serve in the simulation -- one example day\n",
    "tripsfile = base_dir + \"nytrips/nytrips_15180.bz2\"\n",
    "# trips to serve in the simulation -- base filename for all days\n",
    "tripsfile_base = base_dir + \"nytrips/nytrips\"\n",
    "# number of drivers to use (only in the below examples)\n",
    "ndrivers = 6000\n",
    "# maximum waiting time (in seconds)\n",
    "tmax = 300\n",
    "# file containing the frequency distribution of trip start nodes \n",
    "# this can be used as a simple way to relocate drivers in accordance with the overall demand\n",
    "cruising_target_dist_fn = base_dir + \"nytrips/trip_start_dist.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic cases\n",
    "Simulation of one day, with a fixed number of drivers, measure the number of trips successfully served within 5 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simple run, load the trips with the c++ code, no cruising (drivers stay in place after every trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = wte.wait_time_estimator()\n",
    "w.load_index_default_fn(4092, fnbase, use_paths = True)\n",
    "w.load_distances(dist_fn)\n",
    "# note: we filter out too short and too long trips\n",
    "w.read_trips_csv(tripsfile, \"bz2\", length_min = 120, length_max = 7200,\n",
    "                 dist_min = 500, speed_max = 100 / 3.6)\n",
    "\n",
    "# add the drivers\n",
    "w.add_drivers(ndrivers, 0)\n",
    "\n",
    "N = w.ntrips\n",
    "nserved = 0\n",
    "for i in tqdm_notebook(range(N)):\n",
    "    trip = w.get_trip(i)\n",
    "    if w.process_trip(trip, tmax):\n",
    "        nserved += 1\n",
    "\n",
    "total_trip = 0\n",
    "total_empty = 0\n",
    "for d in w.drivers:\n",
    "    total_trip += d['total_trip_distance']\n",
    "    total_empty += d['total_empty_distance']\n",
    "        \n",
    "print('Served {} / {} trips\\n'.format(nserved, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Same, but read the trips with Pandas \n",
    "This can be useful if e.g. additional processing of trips or if there is an issue using the read_trips_csv() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.read_csv(bz2.open(tripsfile), header = None,\n",
    "                    names = ['id','start_ts','end_ts','start_node','end_node'])\n",
    "# filter trips (note that this only takes into account trip length, but not trip speed as above)\n",
    "trips = trips[(trips.start_node != trips.end_node) & (trips.end_ts - trips.start_ts > 120)\n",
    "              & (trips.end_ts - trips.start_ts < 7200)]\n",
    "trips.sort_values('start_ts', inplace = True)\n",
    "\n",
    "N = trips.shape[0]\n",
    "\n",
    "w = wte.wait_time_estimator()\n",
    "w.load_index_default_fn(4092, fnbase, use_paths = True)\n",
    "w.load_distances(dist_fn)\n",
    "\n",
    "# add the drivers -- we cannot use add_drivers(), since that uses the distribution of trip\n",
    "# start locations from trips loaded by the C++ code\n",
    "avgtime = np.mean(trips.end_ts - trips.start_ts)\n",
    "for i in range(ndrivers):\n",
    "    node = trips.iloc[np.random.choice(N)].start_node\n",
    "    t1 = np.round(np.random.exponential(avgtime))\n",
    "    w.add_driver(int(t1), node)\n",
    "\n",
    "nserved = 0\n",
    "for i in tqdm_notebook(range(N)):\n",
    "    if w.process_trip(trips.iloc[i], tmax):\n",
    "        nserved += 1\n",
    "\n",
    "print('Served {} / {} trips'.format(nserved, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use \"cruising\": simple version\n",
    "A static target distribution is read from a file (that contains frequencies for each node), and a relocation target is selected for each driver after finishing a trip. Once reaching the target, drivers stay in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = wte.wait_time_estimator()\n",
    "w.load_index_default_fn(4092, fnbase, use_paths = True)\n",
    "w.load_distances(dist_fn)\n",
    "# note: we filter out too short and too long trips\n",
    "w.read_trips_csv(tripsfile, \"bz2\", length_min = 120, length_max = 7200, dist_min = 500, speed_max = 100 / 3.6)\n",
    "\n",
    "# add the drivers\n",
    "w.add_drivers(ndrivers, 0)\n",
    "\n",
    "w.strategy = wte.wait_time_estimator.cruising_strategy.DRIVER_RANDOM_NODE\n",
    "w.read_cruising_target_dist(0, cruising_target_dist_fn)\n",
    "\n",
    "N = w.ntrips\n",
    "nserved = 0\n",
    "for i in tqdm_notebook(range(N)):\n",
    "    trip = w.get_trip(i)\n",
    "    if w.process_trip(trip, tmax, True):\n",
    "        nserved += 1\n",
    "\n",
    "\n",
    "total_trip = 0\n",
    "total_empty = 0\n",
    "for d in w.drivers:\n",
    "    total_trip += d['total_trip_distance']\n",
    "    total_empty += d['total_empty_distance']\n",
    "        \n",
    "print('Served {} / {} trips\\nTotal trip / empty distance: {} km / {} km'.format(\n",
    "    nserved, N, total_trip / 1000, total_empty / 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation of minimum fleet\n",
    "Iterate the simulation until 95% of the trips are served; determine the minimum number of drivers required for this by a binary search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Helper function to load a set of trips\n",
    "We typically want to use a set of trips between 5am to 5am the next day instead of between midnight. Here, we load two days and do a simple filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trips(base_name, day, hour):\n",
    "    # 1st day\n",
    "    trips1 = pd.read_csv(bz2.open('{}_{}.bz2'.format(base_name, day)), header=None,\n",
    "                         names=['id','start_ts','end_ts','start_node','end_node'])\n",
    "    # 2nd day\n",
    "    trips2 = pd.read_csv(bz2.open('{}_{}.bz2'.format(base_name, day + 1)), header=None,\n",
    "                         names=['id','start_ts','end_ts','start_node','end_node'])\n",
    "    # filter trips based on length\n",
    "    trips1 = trips1[(trips1.start_node != trips1.end_node) & (trips1.end_ts - trips1.start_ts > 120) & (trips1.end_ts - trips1.start_ts < 7200)]\n",
    "    trips2 = trips2[(trips2.start_node != trips2.end_node) & (trips2.end_ts - trips2.start_ts > 120) & (trips2.end_ts - trips2.start_ts < 7200)]\n",
    "    # filter based on time of day\n",
    "    trips1 = trips1[(trips1.start_ts % 86400) >= hour*3600]\n",
    "    trips2 = trips2[(trips2.start_ts % 86400) < hour*3600]\n",
    "    # concatenate\n",
    "    trips = pd.concat([trips1, trips2])\n",
    "    # ensure that the result is properly sorted\n",
    "    trips.sort_values('start_ts', inplace=True)\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Helper function to process one day\n",
    "Given a list of trips, this first subsamples them according to the given factor, then finds the minimum number of drivers required to serve p ratio (e.g. 95%) of trips within the given maximum waiting time (e.g. 5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_day(w1, rng, trips = None, pr_sub = 1.0, p_req = 0.95, twait = 300,\n",
    "                    initial_step = 1000, write_progress = False):\n",
    "    \"\"\"\n",
    "    Estimate fleet size for one instance of one day. Parameters:\n",
    "        w1: a wte.wait_time_estimator class, initialized with the travel times and\n",
    "            optionally with a set of trips\n",
    "        rng: random number generator to use \n",
    "            (for selecting a subset of trips and assigning starting position to drivers)\n",
    "        trips: a pandas.DataFrame with a set of trips to serve or None to use the trips\n",
    "            loaded in w1\n",
    "        pr_sub: ratio of trips to subsample before running\n",
    "        p_req: required ratio of trips to serve\n",
    "        twait: maximum acceptable waiting time (in seconds)\n",
    "        initial_step: initial number of drivers to use\n",
    "        write_progress: whether to write the current progress on each iteration\n",
    "    Returns: tuple with the final fleet size, and numbers of served and unserved trips\n",
    "    \"\"\"\n",
    "    have_trips = (trips is not None)\n",
    "    N = trips.shape[0] if have_trips else w1.ntrips # total number of trips\n",
    "    N1 = N\n",
    "    ids = list(range(N))\n",
    "    if pr_sub < 1.0:\n",
    "        rng.shuffle(ids)\n",
    "        N1 = int(pr_sub * N) # number of trips to use\n",
    "    \n",
    "    binary_search = False\n",
    "    \n",
    "    low = 0\n",
    "    high = 2*initial_step\n",
    "    fleet_size = initial_step\n",
    "    \n",
    "    if have_trips:\n",
    "        avgtime = np.mean(trips.end_ts - trips.start_ts)\n",
    "        start_time = trips.iloc[0].start_ts\n",
    "        start_time -= (start_time % 3600)\n",
    "        \n",
    "    pct = 0.0\n",
    "    matched, unmatched = 0, 0\n",
    "    \n",
    "    # main loop\n",
    "    it = 0\n",
    "    while(True):\n",
    "        matched, unmatched = 0, 0\n",
    "        ndrivers = fleet_size\n",
    "        \n",
    "        # Add drivers\n",
    "        w1.reset(True)\n",
    "        if have_trips:\n",
    "            for i in range(ndrivers):\n",
    "                x = rng.integers(N)\n",
    "                node = trips.iloc[x].start_node\n",
    "                t1 = np.round(rng.exponential(avgtime))\n",
    "                w1.add_driver(start_time + int(t1), node)\n",
    "        else:\n",
    "            w1.add_drivers(ndrivers, 0)\n",
    "        \n",
    "        # Try to serve all selected trips\n",
    "        for i in range(N):\n",
    "            if ids[i] > N1:\n",
    "                continue\n",
    "            t1 = trips.iloc[i] if have_trips else w1.get_trip(i)\n",
    "            if w1.process_trip(t1, tmax):\n",
    "                matched += 1\n",
    "            else:\n",
    "                unmatched += 1\n",
    "        \n",
    "        pct = round(matched / (matched + unmatched), 3)\n",
    "        if pct == p_req:\n",
    "            break\n",
    "        if pct < p_req:\n",
    "            if binary_search:\n",
    "                low = fleet_size\n",
    "            else:\n",
    "                # initial phase, just increase the fleet size\n",
    "                low += initial_step\n",
    "                high += initial_step\n",
    "        else:\n",
    "            high = fleet_size\n",
    "            binary_search = True\n",
    "        new_fleet_size = int((low + high) / 2)\n",
    "        it += 1\n",
    "        if write_progress:\n",
    "            print('Iteration: {}, fleet size: {}, pct: {}\\n'.format(it, fleet_size, pct))\n",
    "        if new_fleet_size == fleet_size:\n",
    "            break # no change anymore\n",
    "        fleet_size = new_fleet_size\n",
    "    return (fleet_size, matched, unmatched)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Example: run the estimation for one day and one subsampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = wte.wait_time_estimator()\n",
    "w.load_index_default_fn(4092, fnbase, use_paths = True)\n",
    "w.load_distances(dist_fn)\n",
    "w.strategy = wte.wait_time_estimator.cruising_strategy.DRIVER_RANDOM_NODE\n",
    "w.read_cruising_target_dist(0, cruising_target_dist_fn)\n",
    "\n",
    "trips = load_trips(tripsfile_base, 15000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "process_one_day(w, rng, trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate version, load the trips in w -- should be significantly faster\n",
    "w.read_trips_csv(\"{}_{}.bz2\".format(tripsfile_base, 15000), compress = \"bz2\",\n",
    "                 tmin = 18000, tlimit_in_day = True, length_min = 120, length_max = 7200,\n",
    "                 dist_min = 500, speed_max = 100 / 3.6, clear_trips = True)\n",
    "w.read_trips_csv(\"{}_{}.bz2\".format(tripsfile_base, 15001), compress = \"bz2\",\n",
    "                 tmax = 17999, tlimit_in_day = True, length_min = 120, length_max = 7200,\n",
    "                 dist_min = 500, speed_max = 100 / 3.6, clear_trips = False)\n",
    "w.sort_trips()\n",
    "\n",
    "process_one_day(w, rng, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run the estimation for three weeks of data and a set of subsampling rates\n",
    "Note: this is only one realization. For a more accurate estimate, repeat this process multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_ny = list(range(15180, 15185)) + list(range(15243, 15248)) + list(range(15187, 15192))\n",
    "sampling_list = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "w = wte.wait_time_estimator()\n",
    "w.load_index_default_fn(4092, fnbase, use_paths = True)\n",
    "w.load_distances(dist_fn)\n",
    "w.strategy = wte.wait_time_estimator.cruising_strategy.DRIVER_RANDOM_NODE\n",
    "w.read_cruising_target_dist(0, cruising_target_dist_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_trips_with_pandas = False # set to true to read trips with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = list()\n",
    "for day in tqdm_notebook(days_ny):\n",
    "    trips = None\n",
    "    if read_trips_with_pandas:\n",
    "        trips = load_trips(tripsfile_base, day, 5)\n",
    "    else:\n",
    "        w.read_trips_csv(\"{}_{}.bz2\".format(tripsfile_base, day), compress = \"bz2\",\n",
    "                 tmin = 18000, tlimit_in_day = True, length_min = 120, length_max = 7200,\n",
    "                 dist_min = 500, speed_max = 100 / 3.6, clear_trips = True)\n",
    "        w.read_trips_csv(\"{}_{}.bz2\".format(tripsfile_base, day + 1), compress = \"bz2\",\n",
    "                 tmax = 17999, tlimit_in_day = True, length_min = 120, length_max = 7200,\n",
    "                 dist_min = 500, speed_max = 100 / 3.6, clear_trips = False)\n",
    "        w.sort_trips()\n",
    "\n",
    "    for pr in tqdm_notebook(sampling_list):\n",
    "        (ndrivers, matched, unmatched) = process_one_day(w, rng, trips, pr)\n",
    "        ntrips = matched + unmatched\n",
    "        res.append({'day': day, 'pr': pr, 'ndrivers': ndrivers, 'ntrips': ntrips,\n",
    "                    'pct_served': matched / ntrips})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Process the previous results\n",
    "Calculate fleet size factors and plot these as a function of subsampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = pd.DataFrame(res)\n",
    "res100 = res2[res2.pr == 1.0]\n",
    "res3 = res2.merge(res100, on = ['day'], suffixes= ['','100'])\n",
    "res3['rdrivers'] = res3['ndrivers'] / res3['ndrivers100']\n",
    "res3['factor'] = res3['rdrivers'] / res3['pr'] - 1 # fleet size factor as defined in Eq. (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all data points\n",
    "res3.plot(x = 'pr', y = 'factor', kind = 'scatter')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
